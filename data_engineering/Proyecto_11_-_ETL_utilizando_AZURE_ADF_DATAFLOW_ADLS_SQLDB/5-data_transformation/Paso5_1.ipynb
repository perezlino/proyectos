{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`Paso 5.1`: Creamos el Data flow `df_transform_cases_deaths` para transformar los datos del archivo `cases_deaths.csv`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Diagrama Data Flow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "          SOURCE                          FILTER                            SELECT                           PIVOT                      LOOKUP                        SELECT                         SINK\n",
    " ________________________          ____________________          ____________________________          _________________          ___________________          ___________________          _______________________\n",
    "|                        |        |                    |        |                            |        |                 |        |                   |        |                   |        |                       |      \n",
    "|  CasesAndDeathsSource  |--------|  FilterEuropeOnly  |--------|  SelectOnlyRequiredFileds  |--------|   PivotCounts   |--------|   LookupCountry   |--------|   SelectForSink   |--------|   CaseAndDeathsSink   |\n",
    "|________________________| +      |____________________| +      |____________________________| +      |_________________| +      |___________________| +      |___________________| +      |_______________________|\n",
    "                                                                                                                                      |    \n",
    "        SOURCE                                                                                                                        |    \n",
    " ___________________                                                                                                                  |    \n",
    "|                   |-----------------------------------------------------------------------------------------------------------------'    \n",
    "|   CountryLookup   |        \n",
    "|___________________|        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Crear un nuevo dataset de origen que haga referencia al archivo `cases_deaths.csv`, llamado  `ds_raw_cases_and_deaths`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 1: Crear un nuevo dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Seleccionar la pestaña \"Author\"**: En el menú de la izquierda dentro de tu Data Factory, haz clic en la pestaña **Author** (Autor).\n",
    "2. **Seleccionar \"Datasets\"**: En el panel de **Author**, haz clic en **Datasets**.\n",
    "3. **Hacer clic en los tres puntos**: Junto a la opción **Datasets**, haz clic en los tres puntos (más opciones).\n",
    "4. **Seleccionar \"New dataset\"**: En el menú desplegable, selecciona **New dataset** para crear un nuevo dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p743.png](https://i.postimg.cc/26Z4n5zc/p743.png)](https://postimg.cc/R6v6B4JK)\n",
    "[![p861.png](https://i.postimg.cc/FRFT7RsM/p861.png)](https://postimg.cc/SX56Pm9d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 2: Configurar el nuevo dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Elegir tipo de dataset**: En la ventana de selección, busca y selecciona `Azure Data Lake Storage Gen2` como el tipo de datastore.\n",
    "2. **Hacer clic en \"Continue\"**: Después de seleccionar `Azure Data Lake Storage Gen2`, haz clic en **Continue** para proceder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p862.png](https://i.postimg.cc/gjn4HTh4/p862.png)](https://postimg.cc/sGCpVKwZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 3: Configurar el formato del dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Seleccionar el formato**: En el campo de selección de formato, elige `DelimitedText`.\n",
    "2. **Hacer clic en \"Continue\"**: Después de seleccionar el formato, haz clic en **Continue**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p863.png](https://i.postimg.cc/bYBmwqX5/p863.png)](https://postimg.cc/dDG2WPVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 4: Configurar las propiedades del dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Crearemos un nuevo dataset **ds_ecdc_raw_csv_dl**, que hará referencia hacia nuestro ADLS y esta vez tendrá un formato de tipo `DelimitedText`. Hara referencia al archivo `cases_deaths.csv` (que no existe aún) que se almacenará en el contenedor `raw` y en el directorio `ecdc` (tampoco existe aún). No importaremos el schema, dado que el archivo aún no existe, no tiene datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Nombre del dataset**: En el campo de nombre, ingresa `ds_raw_cases_and_deaths`.\n",
    "2. **Linked Service**: En el menú desplegable, selecciona el Linked Service que creaste previamente, `ls_adls_covidreportingdl`.\n",
    "3. **File path**: Indiquemos la ruta `raw/ecdc` e ingresa `cases_deaths.csv`.\n",
    "4. **First row as header**: Activar la casilla.\n",
    "5. **Import schema**: Selecciona `From connection/store` para importar un schema.\n",
    "6. **Guardar el dataset**: Haz clic en el botón **OK** para almacenar el nuevo dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p864.png](https://i.postimg.cc/KzdQQ552/p864.png)](https://postimg.cc/vgtWZfjq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 5: Revisar el dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Revisar la lista de datasets**: Deberías ver tu nuevo dataset `ds_raw_cases_and_deaths` en la lista de datasets. Puedes hacer clic en él para revisar su configuración.\n",
    "2. **Revisar el schema**: Podemos visualizar el schema de datos del archivo `cases_deaths.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p865.png](https://i.postimg.cc/8k6Zcq1P/p865.png)](https://postimg.cc/yW7mrpgw)\n",
    "[![p866.png](https://i.postimg.cc/mkCjnFdF/p866.png)](https://postimg.cc/RJCw6qxM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Crear un nuevo dataset de origen que haga referencia al archivo `country_lookup.csv`, llamado  `ds_country_lookup`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 1: Crear un nuevo dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Seleccionar la pestaña \"Author\"**: En el menú de la izquierda dentro de tu Data Factory, haz clic en la pestaña **Author** (Autor).\n",
    "2. **Seleccionar \"Datasets\"**: En el panel de **Author**, haz clic en **Datasets**.\n",
    "3. **Hacer clic en los tres puntos**: Junto a la opción **Datasets**, haz clic en los tres puntos (más opciones).\n",
    "4. **Seleccionar \"New dataset\"**: En el menú desplegable, selecciona **New dataset** para crear un nuevo dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p743.png](https://i.postimg.cc/26Z4n5zc/p743.png)](https://postimg.cc/R6v6B4JK)\n",
    "[![p887.png](https://i.postimg.cc/YqZdBsdY/p887.png)](https://postimg.cc/gnyVvNF2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 2: Configurar el nuevo dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Elegir tipo de dataset**: En la ventana de selección, busca y selecciona `Azure Data Lake Storage Gen2` como el tipo de datastore.\n",
    "2. **Hacer clic en \"Continue\"**: Después de seleccionar `Azure Data Lake Storage Gen2`, haz clic en **Continue** para proceder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p888.png](https://i.postimg.cc/3wC1pJYF/p888.png)](https://postimg.cc/5Hy8WJHX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 3: Configurar el formato del dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Seleccionar el formato**: En el campo de selección de formato, elige `DelimitedText`.\n",
    "2. **Hacer clic en \"Continue\"**: Después de seleccionar el formato, haz clic en **Continue**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p889.png](https://i.postimg.cc/85pHbQCQ/p889.png)](https://postimg.cc/5HrLxrvn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 4: Configurar las propiedades del dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Nombre del dataset**: En el campo de nombre, ingresa `ds_country_lookup`.\n",
    "2. **Linked Service**: En el menú desplegable, selecciona el Linked Service que creaste previamente, `ls_adls_covidreportingdl`.\n",
    "3. **File path**: Indiquemos el contenedor `lookup` e ingresa `country_lookup.csv`.\n",
    "4. **First row as header**: Activar la casilla.\n",
    "5. **Import schema**: Selecciona `From connection/store` para importar un schema.\n",
    "6. **Guardar el dataset**: Haz clic en el botón **OK** para almacenar el nuevo dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p890.png](https://i.postimg.cc/s2RKvZd2/p890.png)](https://postimg.cc/QF0czCML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 5: Revisar el dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Revisar la lista de datasets**: Deberías ver tu nuevo dataset `ds_country_lookup` en la lista de datasets. Puedes hacer clic en él para revisar su configuración.\n",
    "2. **Revisar el schema**: Podemos visualizar el schema de datos del archivo `country_lookup.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p891.png](https://i.postimg.cc/K8TJGDWV/p891.png)](https://postimg.cc/DS2q5Lnd)\n",
    "[![p892.png](https://i.postimg.cc/Y9dxnn44/p892.png)](https://postimg.cc/MMjRXYmx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Crear un nuevo dataset de destino que haga referencia a la ruta `processed/ecdc/cases_deaths`, llamado  `ds_processed_cases_and_deaths`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un nuevo dataset de destino **ds_processed_cases_and_deaths** que haga referencia a la ruta **processed/ecdc/cases_deaths**. El directorio **ecdc** y el subdirectorio **cases_deaths** no existen dentro del contenedor **processed**, por lo que se crearan de manera automática. No se indicó un nombre de archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 1: Crear un nuevo dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Seleccionar la pestaña \"Author\"**: En el menú de la izquierda dentro de tu Data Factory, haz clic en la pestaña **Author** (Autor).\n",
    "2. **Seleccionar \"Datasets\"**: En el panel de **Author**, haz clic en **Datasets**.\n",
    "3. **Hacer clic en los tres puntos**: Junto a la opción **Datasets**, haz clic en los tres puntos (más opciones).\n",
    "4. **Seleccionar \"New dataset\"**: En el menú desplegable, selecciona **New dataset** para crear un nuevo dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p743.png](https://i.postimg.cc/26Z4n5zc/p743.png)](https://postimg.cc/R6v6B4JK)\n",
    "[![p907.png](https://i.postimg.cc/WbBBjn8F/p907.png)](https://postimg.cc/YhxnzQJM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 2: Configurar el nuevo dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Elegir tipo de dataset**: En la ventana de selección, busca y selecciona `Azure Data Lake Storage Gen2` como el tipo de datastore.\n",
    "2. **Hacer clic en \"Continue\"**: Después de seleccionar `Azure Data Lake Storage Gen2`, haz clic en **Continue** para proceder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p908.png](https://i.postimg.cc/8zLqC6Xy/p908.png)](https://postimg.cc/mP2dXtsM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 3: Configurar el formato del dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Seleccionar el formato**: En el campo de selección de formato, elige `DelimitedText`.\n",
    "2. **Hacer clic en \"Continue\"**: Después de seleccionar el formato, haz clic en **Continue**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p909.png](https://i.postimg.cc/JhqvNWLZ/p909.png)](https://postimg.cc/xkX6Qhq1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 4: Configurar las propiedades del dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Nombre del dataset**: En el campo de nombre, ingresa `ds_processed_cases_and_deaths`.\n",
    "2. **Linked Service**: En el menú desplegable, selecciona el Linked Service que creaste previamente, `ls_adls_covidreportingdl`.\n",
    "3. **File path**: Indiquemos el contenedor `processed` e ingresa la ruta `ecdc/cases_deaths`.\n",
    "4. **First row as header**: Activar la casilla.\n",
    "5. **Import schema**: Selecciona `None` para no importar un schema, dado que no existe aún el archivo.\n",
    "6. **Guardar el dataset**: Haz clic en el botón **OK** para almacenar el nuevo dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p910.png](https://i.postimg.cc/jjKBnSGR/p910.png)](https://postimg.cc/gxSgfmz7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 5: Revisar el dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Revisar la lista de datasets**: Deberías ver tu nuevo dataset `ds_processed_cases_and_deaths` en la lista de datasets. Puedes hacer clic en él para revisar su configuración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p911.png](https://i.postimg.cc/nzh5TwF5/p911.png)](https://postimg.cc/B8RMnp1c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Crear un nuevo Data Flow llamado `df_transform_cases_deaths`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 1: Crear un nuevo Data Flow llamado `df_transform_cases_deaths` y agregar la actividad `Source`** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Seleccionar \"Data flows\"**: En el panel de **Author**, haz clic en **Data flows**.\n",
    "2. **Hacer clic en los tres puntos**: Junto a la opción **Data flows**, haz clic en los tres puntos (más opciones).\n",
    "3. **Seleccionar \"New data flow\"**: En el menú desplegable, selecciona **New data flow** para crear un nuevo Data Flow.\n",
    "4. Nombrar el Data Flow como `df_transform_cases_deaths`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p867.png](https://i.postimg.cc/TYS20Lzc/p867.png)](https://postimg.cc/6yrN5357)\n",
    "[![p872.png](https://i.postimg.cc/6q2gp3M9/p872.png)](https://postimg.cc/xNQts0r7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 2: Configurar la actividad `Source` en el Data Flow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Una vez en la página del Data Flow, verás un lienzo en blanco donde puedes agregar actividades. En la parte superior, haz clic en el ícono de **Add Source**.\n",
    "2. **Pestaña Source Settings**:\n",
    "   - En **Output stream name**, ingresa `CasesAndDeathsSource`.\n",
    "   - En **Source type**, selecciona `Dataset`.\n",
    "   - En **Dataset**, selecciona `ds_raw_cases_and_deaths`.\n",
    "\n",
    "2. **Pestaña Projection**:\n",
    "   - Seleccionamos la opción **Detect data type** para que identifique los tipos de datos correctos para cada campo.\n",
    "\n",
    "3. **Pestaña Inspect**:\n",
    "   - Verificamos los tipos de datos de cada campo.\n",
    "\n",
    "4. **Pestaña Preview**:\n",
    "   - Previsualizamos los datos.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p868.png](https://i.postimg.cc/FKXr5tsd/p868.png)](https://postimg.cc/bZLckBnp)\n",
    "[![p869.png](https://i.postimg.cc/qRkpq8Kp/p869.png)](https://postimg.cc/CZ636nJ2)\n",
    "[![p870.png](https://i.postimg.cc/SsDkMJLC/p870.png)](https://postimg.cc/5YYhc9R2)\n",
    "[![p871.png](https://i.postimg.cc/25dzCHVH/p871.png)](https://postimg.cc/LqXdT3kf)\n",
    "[![p876.png](https://i.postimg.cc/7LG152gJ/p876.png)](https://postimg.cc/Mcwf4X3z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 3: Agregar la actividad `Filter` para filtrar el campo `continent` y nos devuelva solo registros para el continente `Europe`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Agregamos la actividad `Filter`\n",
    "2. **Pestaña Filter Settings**:\n",
    "   - En **Output stream name**, ingresa `FilterEuropeOnly`.\n",
    "   - En **Filter on** indicamos la siguiente expresión: `continent == 'Europe' && !isNull(country_code)` también puede ser `continent == 'Europe' && not(isNull(country_code))`.\n",
    "\n",
    "3. **Pestaña Inspect**:\n",
    "   - Verificamos los tipos de datos de cada campo.\n",
    "\n",
    "4. **Pestaña Preview**:\n",
    "   - Previsualizamos los datos.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p873.png](https://i.postimg.cc/MGC7VpDP/p873.png)](https://postimg.cc/Y4xLwkTY)\n",
    "[![p874.png](https://i.postimg.cc/P5Fzf48k/p874.png)](https://postimg.cc/G4GsqvQM)\n",
    "[![p875.png](https://i.postimg.cc/dV0jKX3B/p875.png)](https://postimg.cc/xcWzv6KJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 4: Agregar la actividad `Select` para seleccionar las columnas que necesitamos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Agregamos la actividad `Select`\n",
    "2. **Pestaña Select Settings**:\n",
    "   - En **Output stream name**, ingresa `SelectOnlyRequiredFields`.\n",
    "   - En **Input columns**  eliminamos 3 columnas: `continent`, `date` y `rate_14_day`.\n",
    "   - Luego utilizamos un **Rule-based mapping** para volver a llamar al campo **date** (que habiamos eliminado anteriormente) y le actualizamos su nombre utilizando la expresión **'reported' + '_date'** creandose el campo `reported_date`.\n",
    "\n",
    "3. **Pestaña Inspect**:\n",
    "   - Verificamos los tipos de datos de cada campo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p877.png](https://i.postimg.cc/N0GsD3s1/p877.png)](https://postimg.cc/qNYHMZCR)\n",
    "[![p878.png](https://i.postimg.cc/d1pJqD8B/p878.png)](https://postimg.cc/BLTrpS7L)\n",
    "[![p879.png](https://i.postimg.cc/JhT12p0S/p879.png)](https://postimg.cc/TyDMyqrc)\n",
    "[![p880.png](https://i.postimg.cc/3RdK52DN/p880.png)](https://postimg.cc/62xsC2cx)\n",
    "[![p881.png](https://i.postimg.cc/ZnN40ZHh/p881.png)](https://postimg.cc/sG3t0kbn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 5: Agregar la actividad `Pivot`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Agregamos la actividad `Pivot`\n",
    "2. **Pestaña Pivot Settings**:\n",
    "   - En **Output stream name**, ingresa `PivotCounts`.\n",
    "   - En **Input columns**: \n",
    "      - **Group by**: Agrupamos 5 columnas: `country`, `country_code` y `population`, `source` y `reported_date`.\n",
    "      - **Pivot key**: La columna **Pivot key** sera `indicator`. Indicamos los valores que tiene este campo.\n",
    "      - **Pivoted columns**: La **columna pivoteada** será la suma de valores de `daily_count`. Como **expression prefix** colocamos `count`.\n",
    "\n",
    "3. **Pestaña Inspect**:\n",
    "   - Verificamos los tipos de datos de cada campo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es lo que debemos realizar con la actividad **Pivot**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "1.- Agrupamos columnas \n",
    " _______________________________________________                                       _________________________________________________________________ \n",
    "|country            country_code    population  |    indicator           daily_count  |   reported_date     source                                      |\n",
    "|United Kingdom     GBR             66647112    |    confirmed cases     0            |   2020-01-02        Epidemic intelligence, national daily data  |           \n",
    "|United Kingdom     GBR             66647112    |    deaths              0            |   2020-01-02        Epidemic intelligence, national daily data  |\n",
    "|United Kingdom     GBR             66647112    |    confirmed cases     0            |   2020-01-03        Epidemic intelligence, national daily data  |\n",
    "|United Kingdom     GBR             66647112    |    deaths              0            |   2020-01-03        Epidemic intelligence, national daily data  |\n",
    "|United Kingdom     GBR             66647112    |    confirmed cases     0            |   2020-01-04        Epidemic intelligence, national daily data  |\n",
    "|United Kingdom     GBR             66647112    |    deaths              0            |   2020-01-04        Epidemic intelligence, national daily data  |\n",
    "|_______________________________________________|                                     |_________________________________________________________________|\n",
    "\n",
    "2.- Elegimos una columna PIVOT KEY: indicator\n",
    "\n",
    "3.- Elegimos la(s) columna PIVOTEADA: daily_count\n",
    " __________________________________________________________________________________________________________________________________________________________\n",
    "|country            country_code    population      reported_date     source                                        confirmed cases_count   deaths_count   |                   \n",
    "|United Kingdom     GBR             66647112        2020-01-02        Epidemic intelligence, national daily data    0                       0              | \n",
    "|United Kingdom     GBR             66647112        2020-01-03        Epidemic intelligence, national daily data    0                       0              | \n",
    "|United Kingdom     GBR             66647112        2020-01-04        Epidemic intelligence, national daily data    0                       0              | \n",
    "|__________________________________________________________________________________________________________________________________________________________|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de los datos que tenemos hasta el momento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.postimg.cc/G2HGFP9G/adf806.png\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/HxR5BJ7K/adf807.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p882.png](https://i.postimg.cc/4d2CT1KM/p882.png)](https://postimg.cc/VrtZqnWB)\n",
    "[![p883.png](https://i.postimg.cc/Gt6Z4hxx/p883.png)](https://postimg.cc/jnQ89T9D)\n",
    "[![p884.png](https://i.postimg.cc/BZyWYMfP/p884.png)](https://postimg.cc/rzSYzGmq)\n",
    "[![p885.png](https://i.postimg.cc/L5Jc4ZLs/p885.png)](https://postimg.cc/m1GX8kdx)\n",
    "[![p886.png](https://i.postimg.cc/02JTLD9W/p886.png)](https://postimg.cc/zV82hLbK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 6: Agregar una nueva actividad `Source`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Pestaña Source Settings**:\n",
    "   - En **Output stream name**, ingresa `CountryLookup`.\n",
    "   - En **Source type**, selecciona `Dataset`.\n",
    "   - En **Dataset**, selecciona `ds_country_lookup`.\n",
    "\n",
    "2. **Pestaña Projection**:\n",
    "   - Seleccionamos la opción **Detect data type** para que identifique los tipos de datos correctos para cada campo.\n",
    "\n",
    "3. **Pestaña Inspect**:\n",
    "   - Verificamos los tipos de datos de cada campo.\n",
    "\n",
    "4. **Pestaña Preview**:\n",
    "   - Previsualizamos los datos.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p893.png](https://i.postimg.cc/MHkrb3gy/p893.png)](https://postimg.cc/Pp44dyXx)\n",
    "[![p894.png](https://i.postimg.cc/FzjCPgQw/p894.png)](https://postimg.cc/zHGkvhvk)\n",
    "[![p895.png](https://i.postimg.cc/fTNrVFcs/p895.png)](https://postimg.cc/dD5BX5NN)\n",
    "[![p896.png](https://i.postimg.cc/Y2gPqkm8/p896.png)](https://postimg.cc/Lh9DNcDZ)\n",
    "[![p897.png](https://i.postimg.cc/3JFbmB1v/p897.png)](https://postimg.cc/56j3M8Z4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 7: Agregar una nueva actividad `Lookup`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Agregamos la actividad `Lookup`\n",
    "2. **Pestaña Lookup Settings**:\n",
    "   - En **Output stream name** ingresa `LookupCountry`.\n",
    "   - En **Primary stream** selecciona `PivotCounts`.\n",
    "   - En **Lookup stream** selecciona `CountryLookup`.   \n",
    "   - En **Lookup conditions**: Haremos el match entre el campo `country_code` de la actividad `PivotCounts` y el campo `country_code_3_digit` de la actividad `CountryLookup`.\n",
    "\n",
    "3. **Pestaña Inspect**:\n",
    "   - Verificamos los tipos de datos de cada campo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p898.png](https://i.postimg.cc/5yP0HrPm/p898.png)](https://postimg.cc/2LZmM0Nq)\n",
    "[![p899.png](https://i.postimg.cc/9FMz3WMg/p899.png)](https://postimg.cc/rzBqx255)\n",
    "[![p900.png](https://i.postimg.cc/xjgqFk0b/p900.png)](https://postimg.cc/XXGVrYBV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 8: Agregar una nueva actividad `Select` para seleccionar las columnas** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Agregamos la actividad `Select`\n",
    "2. **Pestaña Select Settings**:\n",
    "   - En **Output stream name** ingresa `SelectForSink`.\n",
    "   - En **Input columns** eliminamos 4 campos: `country_code`, `country`, `continent` y `population`.\n",
    "\n",
    "3. **Pestaña Inspect**:\n",
    "   - Verificamos los tipos de datos de cada campo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p901.png](https://i.postimg.cc/W1sVR8XN/p901.png)](https://postimg.cc/ppc4zDw4)\n",
    "[![p903.png](https://i.postimg.cc/x1g29m4K/p903.png)](https://postimg.cc/RW38RW9F)\n",
    "[![p904.png](https://i.postimg.cc/tgTHJgK8/p904.png)](https://postimg.cc/MnhLrzKY)\n",
    "[![p905.png](https://i.postimg.cc/43SR9gZy/p905.png)](https://postimg.cc/HJXhqFr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 9: Agregar una actividad `Sink`** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Agregamos la actividad `Sink`\n",
    "2. **Pestaña Sink**:\n",
    "   - En **Output stream name**, ingresa `CasesAndDeathsSink`.\n",
    "   - En **Source type**, selecciona `Dataset`.\n",
    "   - En **Dataset**, selecciona `ds_processed_cases_and_deaths`.\n",
    "\n",
    "3. **Pestaña Settings**:\n",
    "   - Seleccionamos la opción **Clear folder** para que borre todo en la ruta antes de crear el archivo.\n",
    "   - En **File name option** seleccionamos `Output to single file`.\n",
    "   - En **Output to single file** ingresamos `case_and_deaths.csv`.   \n",
    "\n",
    "4. **Pestaña Optimize**:\n",
    "   - Seleccionamos la opción `single partition`. \n",
    "\n",
    "5. **Pestaña Inspect**:\n",
    "   - Verificamos los tipos de datos de cada campo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p912.png](https://i.postimg.cc/2SPh0qzf/p912.png)](https://postimg.cc/v4t4BZgP)\n",
    "[![p913.png](https://i.postimg.cc/8CMW915f/p913.png)](https://postimg.cc/qtBzCH2p)\n",
    "[![p914.png](https://i.postimg.cc/9fHtWxrk/p914.png)](https://postimg.cc/87wr4mdd)\n",
    "[![p925.png](https://i.postimg.cc/nLKKMvmh/p925.png)](https://postimg.cc/xkCN4Ngw)\n",
    "[![p915.png](https://i.postimg.cc/rm94yQ58/p915.png)](https://postimg.cc/cgrCX7Dj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Crear el Pipeline de ingesta de datos `pl_process_cases_and_deaths_data` para ejecutar el Data flow recien creado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 1: Crear un nuevo Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Seleccionar la pestaña \"Author\"**: En el menú de la izquierda dentro de tu Data Factory, haz clic en la pestaña **Author** (Autor).\n",
    "2. **Seleccionar \"Pipelines\"**: En el panel de Authoring, haz clic en **Pipelines**.\n",
    "3. **Hacer clic en los tres puntos**: Junto a la opción **Pipelines**, haz clic en los tres puntos (más opciones).\n",
    "4. **Seleccionar \"New pipeline\"**: En el menú desplegable, selecciona **New pipeline** para crear un nuevo pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p743.png](https://i.postimg.cc/26Z4n5zc/p743.png)](https://postimg.cc/R6v6B4JK)\n",
    "[![p916.png](https://i.postimg.cc/9059c08j/p916.png)](https://postimg.cc/qhwqLJHm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 2: Configurar y agregar la actividad `Data Flow` el nuevo Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Asignar un nombre al Pipeline**: En la parte superior derecha, cambia el nombre del pipeline a `pl_process_cases_and_deaths_data`.\n",
    "2. **Buscar la actividad \"Data Flow\"**: En el panel de actividades a la izquierda, busca `Data Flow` en la sección de `Move and transform`.\n",
    "3. **Arrastrar la actividad al canvas**: Arrastra la actividad `Data Flow` al canvas del pipeline.\n",
    "4. **Pestaña General**:\n",
    "   - En **Name**, ingresa `Data Flow Transform Cases And Deaths`.\n",
    "5. **Pestaña Settings**:\n",
    "   - En  **Data flow** seleccionamos `ds_transform_case_deaths`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p917.png](https://i.postimg.cc/sxYhxzqG/p917.png)](https://postimg.cc/y3NdpMV7)\n",
    "[![p918.png](https://i.postimg.cc/Y2YgbN02/p918.png)](https://postimg.cc/3Wrdwv2z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 3: Validar el Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Validar la Configuración**: En la parte superior del panel, haz clic en el botón **\"Validate\"** para comprobar que no haya errores en la configuración del pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p919.png](https://i.postimg.cc/xTPmS0LW/p919.png)](https://postimg.cc/2VVyQNcw)\n",
    "[![p920.png](https://i.postimg.cc/MKwB4cf7/p920.png)](https://postimg.cc/CdvdnxN5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 4: Ejecutar el Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Ejecutar el Pipeline**: Haz clic en el botón **\"Debug\"** en la parte superior para ejecutar el pipeline en modo de depuración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p921.png](https://i.postimg.cc/cJvtYwPS/p921.png)](https://postimg.cc/XZ0v6GVH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 5: Revisar los Resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Verificamos los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p922.png](https://i.postimg.cc/wBnyk3ds/p922.png)](https://postimg.cc/R3QZSShM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 6: Verificar la creación del archivo en la ruta `ecdc/cases_deaths`en el ADLS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Nos dirigimos al ADLS y revisamos la ruta **ecdc/cases_deaths** para ver si se creó el archivo `case_and_deaths.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p923.png](https://i.postimg.cc/jdN4G0jf/p923.png)](https://postimg.cc/rKV4rHxy)\n",
    "[![p924.png](https://i.postimg.cc/K82DbqKH/p924.png)](https://postimg.cc/ykLZXTym)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
