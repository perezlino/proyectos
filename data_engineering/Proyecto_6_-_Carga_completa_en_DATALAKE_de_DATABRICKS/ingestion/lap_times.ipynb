{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"1d086d17-8f9f-4c81-8473-1e56668cbad9","showTitle":false,"title":""}},"source":["## **Ingesta del directorio `lap_times`**"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"eb0e606c-f93e-480a-ada1-8e01a700e513","showTitle":false,"title":""}},"outputs":[],"source":["# Creamos un parametro para el nombre del archivo\n","dbutils.widgets.text(\"p_data_source\", \"\")\n","v_data_source = dbutils.widgets.get(\"p_data_source\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"92b7a85c-6ee0-435b-b4da-3256de58cc3b","showTitle":false,"title":""}},"outputs":[],"source":["# Creamos un parametro para la fecha del archivo\n","dbutils.widgets.text(\"p_file_date\", \"\")\n","v_file_date = dbutils.widgets.get(\"p_file_date\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e2ca5b5f-08fc-448a-9235-b2efc86a78b7","showTitle":false,"title":""}},"outputs":[],"source":["# Llamamos al notebook que contiene las variables de configuración\n","%run \"../utils/configuration\""]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"dde21d5d-33a4-485e-ad34-29ee8ba6a595","showTitle":false,"title":""}},"outputs":[],"source":["# Llamamos al notebook que contiene funciones comunes\n","%run \"../utils/common_functions\""]},{"cell_type":"markdown","metadata":{},"source":["### Paso 1 - Crear tabla **f1_raw.lap_times**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%sql\n","DROP TABLE IF EXISTS f1_raw.lap_times;\n","CREATE EXTERNAL TABLE IF NOT EXISTS f1_raw.lap_times(\n","raceId INT,\n","driverId INT,\n","lap INT,\n","position INT,\n","time STRING,\n","milliseconds INT\n",")\n","USING CSV\n","OPTIONS (path \"/mnt/formula1dl/raw/lap_times\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c10a9b41-e54b-4be3-9579-680b36628fdb","showTitle":false,"title":""}},"source":["### Paso 2 - Leer el directorio **lap_times** el cual contiene multiples archivos CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"e96f6f6e-23b4-400b-a056-1a6acb01c9ab","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql.types import StructType, StructField, IntegerType, StringType"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"c3a4491a-b952-4196-969b-bf5c7965b4b0","showTitle":false,"title":""}},"outputs":[],"source":["lap_times_schema = StructType(fields=[StructField(\"raceId\", IntegerType(), False),\n","                                      StructField(\"driverId\", IntegerType(), True),\n","                                      StructField(\"lap\", IntegerType(), True),\n","                                      StructField(\"position\", IntegerType(), True),\n","                                      StructField(\"time\", StringType(), True),\n","                                      StructField(\"milliseconds\", IntegerType(), True)\n","                                     ])"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"03a2f953-b4a0-46f0-880e-ed3bfd3b1b1a","showTitle":false,"title":""}},"outputs":[],"source":["# El parámetro \"raw_folder_path\" se encuentra en el notebook \"configuration\"\n","# El parámetro \"v_file_date\" se encuentra en el notebook e indicamos su valor en tiempo de ejecución\n","lap_times_df = spark.read \\\n",".schema(lap_times_schema) \\\n",".csv(f\"{raw_folder_path}/lap_times\")\n","#.csv(f\"{raw_folder_path}/{v_file_date}/lap_times\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"11a12637-558c-4342-8375-821d65060739","showTitle":false,"title":""}},"source":["### Paso 3 - Renombrar columnas y añadir nuevas columnas"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"dabce6bd-f30c-4206-849a-abd21eeb5abf","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql.functions import lit"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"03cb7b0b-f159-423d-8e7c-e44bbdb367d5","showTitle":false,"title":""}},"outputs":[],"source":["# La función \"add_ingestion_date()\" se encuentra en el notebook \"common_functions\"\n","# La fecha de ingestión será del tipo timestamp\n","lap_times_with_ingestion_date_df = add_ingestion_date(lap_times_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"3f9f833e-aee5-47df-b553-da43dbefc16b","showTitle":false,"title":""}},"outputs":[],"source":["final_df = lap_times_with_ingestion_date_df.withColumnRenamed(\"driverId\", \"driver_id\") \\\n","                                           .withColumnRenamed(\"raceId\", \"race_id\") \\\n","                                           .withColumn(\"data_source\", lit(v_data_source)) \\\n","                                           .withColumn(\"file_date\", lit(v_file_date))"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"2322063f-9693-4033-b70d-df6091c05224","showTitle":false,"title":""}},"source":["### Paso 4 - Escribir datos en el datalake como parquet y crear la tabla **lap_times** en la base de datos **f1_processed**"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"93eb95a9-06e0-4844-b75e-f662bc082561","showTitle":false,"title":""}},"outputs":[],"source":["# Recordar que Databricks utiliza Hive para la gestión de tablas\n","# Esto quiere decir que una tabla en Hive se asocia con un directorio específico que contiene archivos de datos\n","# Aunque los datos subyacentes son solo archivos en un sistema de archivos, Hive proporciona una interfaz que presenta \n","# estos datos como tablas.\n","# La base de datos tambien es un directorio. Podemos crearla manualmente, como con lenguaje SQL.\n","# Hive permite a los usuarios interactuar con esos datos utilizando un lenguaje similar a SQL\n","# En resumen, solo se esta creando un directorio y un archivo\n","# Escribimos los archivos del directorio \"lap_times\" con formato PARQUET en la base de datos \"f1_processed\" y en la tabla \"lap_times\"\n","final_df.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"f1_processed.lap_times\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"4ef0cc94-b402-4d9c-a00b-3297cbd844de","showTitle":false,"title":""}},"outputs":[],"source":["dbutils.notebook.exit(\"Success\")"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":1345273083809092,"dataframes":["_sqldf"]},"pythonIndentUnit":2},"notebookName":"Paso 2.7 (1)","widgets":{"p_data_source":{"currentValue":"Eargast","nuid":"81fd657c-dcc2-485a-afda-409b05f04266","widgetInfo":{"defaultValue":"","label":null,"name":"p_data_source","options":{"validationRegex":null,"widgetType":"text"},"widgetType":"text"}},"p_file_date":{"currentValue":"2023-06-11","nuid":"723ec5ff-704b-49d9-aee2-e5955408a0a1","widgetInfo":{"defaultValue":"2021-03-21","label":null,"name":"p_file_date","options":{"validationRegex":null,"widgetType":"text"},"widgetType":"text"}}}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
