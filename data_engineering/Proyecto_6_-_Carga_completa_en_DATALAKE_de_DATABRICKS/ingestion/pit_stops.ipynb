{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"1d086d17-8f9f-4c81-8473-1e56668cbad9","showTitle":false,"title":""}},"source":["## **Ingesta del archivo `pit_stops.json`**"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"ccb88611-c557-4c0b-9daf-f525f5d45fb6","showTitle":false,"title":""}},"outputs":[],"source":["# Creamos un parametro para el nombre del archivo\n","dbutils.widgets.text(\"p_data_source\", \"\")\n","v_data_source = dbutils.widgets.get(\"p_data_source\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"797d8733-e7b2-4502-9a48-b151245ce871","showTitle":false,"title":""}},"outputs":[],"source":["# Creamos un parametro para la fecha del archivo\n","dbutils.widgets.text(\"p_file_date\", \"\")\n","v_file_date = dbutils.widgets.get(\"p_file_date\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a8cf65f9-ca3c-40c1-ad62-25506e583f92","showTitle":false,"title":""}},"outputs":[],"source":["# Llamamos al notebook que contiene las variables de configuración\n","%run \"../utils/configuration\""]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"fee364e9-d24b-4021-96f0-9b6d235d10dd","showTitle":false,"title":""}},"outputs":[],"source":["# Llamamos al notebook que contiene funciones comunes\n","%run \"../utils/common_functions\""]},{"cell_type":"markdown","metadata":{},"source":["### Paso 1 - Crear tabla **f1_raw.pit_stops**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%sql\n","DROP TABLE IF EXISTS f1_raw.pit_stops;\n","CREATE EXTERNAL TABLE IF NOT EXISTS f1_raw.pit_stops(\n","driverId INT,\n","duration STRING,\n","lap INT,\n","milliseconds INT,\n","raceId INT,\n","stop INT,\n","time STRING)\n","USING JSON\n","OPTIONS(path \"/mnt/formula1dl/raw/pit_stops.json\", multiLine true)"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c10a9b41-e54b-4be3-9579-680b36628fdb","showTitle":false,"title":""}},"source":["### Paso 2 - Leer el archivo JSON"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"e96f6f6e-23b4-400b-a056-1a6acb01c9ab","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql.types import StructType, StructField, IntegerType, StringType"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"c3a4491a-b952-4196-969b-bf5c7965b4b0","showTitle":false,"title":""}},"outputs":[],"source":["pit_stops_schema = StructType(fields=[StructField(\"raceId\", IntegerType(), False),\n","                                      StructField(\"driverId\", IntegerType(), True),\n","                                      StructField(\"stop\", StringType(), True),\n","                                      StructField(\"lap\", IntegerType(), True),\n","                                      StructField(\"time\", StringType(), True),\n","                                      StructField(\"duration\", StringType(), True),\n","                                      StructField(\"milliseconds\", IntegerType(), True)\n","                                     ])"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"03a2f953-b4a0-46f0-880e-ed3bfd3b1b1a","showTitle":false,"title":""}},"outputs":[],"source":["# El parámetro \"raw_folder_path\" se encuentra en el notebook \"configuration\"\n","# El parámetro \"v_file_date\" se encuentra en el notebook e indicamos su valor en tiempo de ejecución\n","pit_stops_df = spark.read \\\n",".schema(pit_stops_schema) \\\n",".option(\"multiLine\", True) \\\n",".json(f\"{raw_folder_path}/pit_stops.json\")\n","#.json(f\"{raw_folder_path}/{v_file_date}/pit_stops.json\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"e1511646-dec0-43be-9ba4-cf0d5a4293a4","showTitle":false,"title":""}},"source":["### Paso 3 - Renombrar columnas y añadir nuevas columnas"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"84f06840-eb81-40db-84ab-5cda6c92ebd1","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql.functions import lit"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"3f9f833e-aee5-47df-b553-da43dbefc16b","showTitle":false,"title":""}},"outputs":[],"source":["pit_stops_new_df = pit_stops_df.withColumnRenamed(\"driverId\", \"driver_id\") \\\n","                               .withColumnRenamed(\"raceId\", \"race_id\") \\\n","                               .withColumn(\"data_source\", lit(v_data_source)) \\\n","                               .withColumn(\"file_date\", lit(v_file_date))"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"f912fbc0-9a0d-4586-b6fc-a11d3767f762","showTitle":false,"title":""}},"outputs":[],"source":["# La función \"add_ingestion_date()\" se encuentra en el notebook \"common_functions\"\n","# La fecha de ingestión será del tipo timestamp\n","pit_stops_with_ingestion_date_df = add_ingestion_date(pit_stops_new_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"6d112862-53b0-486c-b74e-4bf214ca0527","showTitle":false,"title":""}},"outputs":[],"source":["final_df = pit_stops_with_ingestion_date_df"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"2322063f-9693-4033-b70d-df6091c05224","showTitle":false,"title":""}},"source":["### Paso 4 - Escribir datos en el datalake como parquet y crear la tabla **pit_stops** en la base de datos **f1_processed**"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"0bbcf523-6dc9-4c9e-a885-ebd36528a6e3","showTitle":false,"title":""}},"outputs":[],"source":["# Recordar que Databricks utiliza Hive para la gestión de tablas\n","# Esto quiere decir que una tabla en Hive se asocia con un directorio específico que contiene archivos de datos\n","# Aunque los datos subyacentes son solo archivos en un sistema de archivos, Hive proporciona una interfaz que presenta \n","# estos datos como tablas.\n","# La base de datos tambien es un directorio. Podemos crearla manualmente, como con lenguaje SQL.\n","# Hive permite a los usuarios interactuar con esos datos utilizando un lenguaje similar a SQL\n","# En resumen, solo se esta creando un directorio y un archivo\n","# Escribimos el archivo con formato PARQUET en la base de datos \"f1_processed\" y en la tabla \"pit_stops\"\n","final_df.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"f1_processed.pit_stops\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"01a64f4a-8886-4ee8-b0f8-4f44a9062980","showTitle":false,"title":""}},"outputs":[],"source":["dbutils.notebook.exit(\"Success\")"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":1345273083809061,"dataframes":["_sqldf"]},"pythonIndentUnit":2},"notebookName":"Paso 2.6 (1)","widgets":{"p_data_source":{"currentValue":"Ergast","nuid":"e593fd36-4778-4daa-b594-c095b1021b4b","widgetInfo":{"defaultValue":"","label":null,"name":"p_data_source","options":{"validationRegex":null,"widgetType":"text"},"widgetType":"text"}},"p_file_date":{"currentValue":"2023-06-11","nuid":"6cfa4885-3815-4a9e-9eed-342fcbb9c2c1","widgetInfo":{"defaultValue":"2021-03-28","label":null,"name":"p_file_date","options":{"validationRegex":null,"widgetType":"text"},"widgetType":"text"}}}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
