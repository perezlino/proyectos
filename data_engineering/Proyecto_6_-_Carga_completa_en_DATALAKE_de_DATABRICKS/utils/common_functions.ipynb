{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"d3074eb6-c62e-4d9f-bed5-ec4902fa6308","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql.functions import current_timestamp\n","def add_ingestion_date(input_df):\n","  output_df = input_df.withColumn(\"ingestion_date\", current_timestamp())\n","  return output_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def re_arrange_partition_column(input_df, partition_column):\n","  column_list = []\n","  for column_name in input_df.schema.names:\n","    if column_name != partition_column: # Si \"column_name\" es distinto a \"race_id\"\n","      column_list.append(column_name)  # Lo añadirá a la lista \"column_list\"\n","  column_list.append(partition_column) # Despues de ejecutarse el FOR, agrega a la lista \"column_list\" el valor de \"race_id\" al último\n","  output_df = input_df.select(column_list)\n","  return output_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def overwrite_partition(input_df, db_name, table_name, partition_column):\n","  output_df = re_arrange_partition_column(input_df, partition_column)\n","  spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\",\"dynamic\")\n","  if (spark._jsparkSession.catalog().tableExists(f\"{db_name}.{table_name}\")):\n","    output_df.write.mode(\"overwrite\").insertInto(f\"{db_name}.{table_name}\")\n","  else:\n","    output_df.write.mode(\"overwrite\").partitionBy(partition_column).format(\"parquet\").saveAsTable(f\"{db_name}.{table_name}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# se utiliza en transformacion_incremental --> driver_standings\n","def df_column_to_list(input_df, column_name):\n","  df_row_list = input_df.select(column_name) \\\n","                        .distinct() \\\n","                        .collect()\n","  \n","  column_value_list = [row[column_name] for row in df_row_list]\n","  return column_value_list"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"common_functions","widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
