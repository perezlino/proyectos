{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"b4a281e5-c5a5-4ebd-a848-c884136fb51e","showTitle":false,"title":""}},"source":["## **Transformar datos para obtener resultados de carreras organizados**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creamos un parametro para la fecha del archivo\n","dbutils.widgets.text(\"p_file_date\", \"\")\n","v_file_date = dbutils.widgets.get(\"p_file_date\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Llamamos al notebook que contiene las variables de configuración\n","%run \"../utils/configuration\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Llamamos al notebook que contiene funciones comunes\n","%run \"../includes/common_functions\""]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"5b2addf1-d81d-42ac-a5ee-f9e15689804d","showTitle":false,"title":""}},"source":["### Paso 1 - Leer **drivers** de la capa **processed**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pyspark.sql.functions import current_timestamp"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"5f9b33a8-00b3-450f-8f34-8ae02e168a4e","showTitle":false,"title":""}},"outputs":[],"source":["# El parámetro \"processed_folder_path\" se encuentra en el notebook \"configuration\"\n","drivers_df = spark.read.parquet(f\"{processed_folder_path}/drivers\") \\\n",".withColumnRenamed(\"number\", \"driver_number\") \\\n",".withColumnRenamed(\"name\", \"driver_name\") \\\n",".withColumnRenamed(\"nationality\", \"driver_nationality\") "]},{"cell_type":"markdown","metadata":{},"source":["### Paso 2 - Leer **constructors** de la capa **processed**"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"1e1f003e-4cac-44ec-bc9d-6acfa5bbd321","showTitle":false,"title":""}},"outputs":[],"source":["# El parámetro \"processed_folder_path\" se encuentra en el notebook \"configuration\"\n","constructors_df = spark.read.parquet(f\"{processed_folder_path}/constructors\") \\\n",".withColumnRenamed(\"name\", \"team\") "]},{"cell_type":"markdown","metadata":{},"source":["### Paso 3 - Leer **circuits** de la capa **processed**"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"6d8b4aa5-ef46-4a39-b475-b8b406c5bddd","showTitle":false,"title":""}},"outputs":[],"source":["# El parámetro \"processed_folder_path\" se encuentra en el notebook \"configuration\"\n","circuits_df = spark.read.parquet(f\"{processed_folder_path}/circuits\") \\\n",".withColumnRenamed(\"location\", \"circuit_location\") "]},{"cell_type":"markdown","metadata":{},"source":["### Paso 4 - Leer **races** de la capa **processed**"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"45265110-2097-431a-91a7-44d659c5df10","showTitle":false,"title":""}},"outputs":[],"source":["# El parámetro \"processed_folder_path\" se encuentra en el notebook \"configuration\"\n","races_df = spark.read.parquet(f\"{processed_folder_path}/races\") \\\n",".withColumnRenamed(\"name\", \"race_name\") \\\n",".withColumnRenamed(\"race_timestamp\", \"race_date\") "]},{"cell_type":"markdown","metadata":{},"source":["### Paso 5 - Leer **results** de la capa **processed**"]},{"cell_type":"markdown","metadata":{},"source":["Agregamos la función **filter** para filtrar la data por la fecha, ya sea, **2021-03-21**, **2021-03-28** o **2021-04-18**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# El parámetro \"processed_folder_path\" se encuentra en el notebook \"configuration\"\n","results_df = spark.read.parquet(f\"{processed_folder_path}/results\") \\\n",".filter(f\"file_date = '{v_file_date}'\") \\\n",".withColumnRenamed(\"time\", \"race_time\") \\\n",".withColumnRenamed(\"race_id\", \"result_race_id\") \\\n",".withColumnRenamed(\"file_date\", \"result_file_date\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"41d1ebe5-4470-496a-84b4-8085d53ae94f","showTitle":false,"title":""}},"source":["### Paso 6 - Realizar Join entre **circuits** y **races**"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"388f5e91-e4b0-4ad6-84fc-5f6a65da6dac","showTitle":false,"title":""}},"outputs":[],"source":["race_circuits_df = races_df.join(circuits_df, races_df.circuit_id == circuits_df.circuit_id, \"inner\") \\\n","                           .select(races_df.race_id, races_df.race_year, races_df.race_name, races_df.race_date, circuits_df.circuit_location)"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"a5fe4fa1-caa2-4f72-83ae-7b5deb7e4e2f","showTitle":false,"title":""}},"source":["### Paso 7 - Realizar Join entre el **resultado previo**, **results**, **drivers** y **constructors**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["race_results_df = results_df.join(race_circuits_df, results_df.result_race_id == race_circuits_df.race_id) \\\n","                            .join(drivers_df, results_df.driver_id == drivers_df.driver_id) \\\n","                            .join(constructors_df, results_df.constructor_id == constructors_df.constructor_id)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["final_df = race_results_df.select(\"race_id\",\"race_year\", \"race_name\", \"race_date\", \"circuit_location\", \"driver_name\", \"driver_number\", \"driver_nationality\",\n","                                  \"team\", \"grid\", \"fastest_lap\", \"race_time\", \"points\", \"position\", \"file_date\") \\\n","                          .withColumn(\"created_date\",current_timestamp())"]},{"cell_type":"markdown","metadata":{},"source":["### Paso 7 - Escribir datos en el datalake como **parquet** y crear la tabla **race_results** en la base de datos **f1_presentation**"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"04a51ad4-98b2-486d-8570-219cff1299b3","showTitle":false,"title":""}},"outputs":[],"source":["# La función \"overwrite_partition()\" se encuentra en el notebook \"common_functions\"\n","# Recordar que esta función se llamará al utilizar %run \"../includes/common_functions\"\n","overwrite_partition(final_df, 'f1_presentation', 'race_results', 'race_id')"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":2940602588232326,"dataframes":["_sqldf"]},"pythonIndentUnit":2},"notebookName":"Paso 3.1","widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
