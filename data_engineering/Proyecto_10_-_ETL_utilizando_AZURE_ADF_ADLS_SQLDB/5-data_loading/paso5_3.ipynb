{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`Paso 5.3`: Creación de Pipeline `pl_Copy_Valid_IPL_To_SQL`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Creación y configuración de un nuevo Pipeline que se llamará `pl_Copy_Valid_IPL_To_SQL` que nos permitirá realizar la carga del archivo `ipl 2008.json` en la tabla `dbo.tbl_IPLData`. Agregaremos la actividad `Copy Data`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 1: Crear un nuevo Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Seleccionar la pestaña \"Author\"**: En el menú de la izquierda dentro de tu Data Factory, haz clic en la pestaña **Author** (Autor).\n",
    "2. **Seleccionar \"Pipelines\"**: En el panel de Authoring, haz clic en **Pipelines**.\n",
    "3. **Hacer clic en los tres puntos**: Junto a la opción **Pipelines**, haz clic en los tres puntos (más opciones).\n",
    "4. **Seleccionar \"New pipeline\"**: En el menú desplegable, selecciona **New pipeline** para crear un nuevo pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p656.png](https://i.postimg.cc/Kc652nzt/p656.png)](https://postimg.cc/BtCF5P2v)\n",
    "[![p657.png](https://i.postimg.cc/P5hzLT1x/p657.png)](https://postimg.cc/2VcBMpcR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 2: Configurar el nuevo Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Asignar un nombre al Pipeline**: En la parte superior derecha, cambia el nombre del pipeline a `pl_Copy_IPL_To_SQL`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p658.png](https://i.postimg.cc/x1RGMhPP/p658.png)](https://postimg.cc/211BfHMq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 3: Agregar la Actividad `Copy Data`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Buscar la actividad \"Copy Data\"**: En el panel de actividades a la izquierda, busca **Copy Data** en la sección de **Move and transform**.\n",
    "2. **Arrastrar la actividad al canvas**: Arrastra la actividad **Copy Data** al canvas del pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p659.png](https://i.postimg.cc/5t2B3g7W/p659.png)](https://postimg.cc/mPK1ZYWm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 4: Configurar la Actividad `Copy Data`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Seleccionar la actividad \"Copy Data\"**: Haz clic en la actividad que agregaste para abrir el panel de configuración.\n",
    "2. **Pestaña General**:\n",
    "   - En **Name**, ingresa `Copy IPL data To SQL DB`.\n",
    "\n",
    "3. **Pestaña Source**:\n",
    "   - Cambia a la pestaña **Source**.\n",
    "   - En **Source dataset**, selecciona `ds_Valid_IPL_Data_Json`. \n",
    "\n",
    "4. **Pestaña Sink**:\n",
    "   - Cambia a la pestaña **Sink**.\n",
    "   - En **Sink dataset**, selecciona `ds_AzureSqlTable_IPL_Data`.\n",
    "\n",
    "5. **Pestaña Mapping**:\n",
    "   - Realizamos el mapeo de las columnas del archivo `ipl 2008.json` frente a las columnas de la tabla `dbo.tbl_IPLData`\n",
    "   - Eliminamos la columna **Date**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p660.png](https://i.postimg.cc/9fgGN9KR/p660.png)](https://postimg.cc/DWsJSS2n)\n",
    "[![p661.png](https://i.postimg.cc/PxLmGxn6/p661.png)](https://postimg.cc/dkY7rJ1d)\n",
    "[![p662.png](https://i.postimg.cc/cCwwHbHw/p662.png)](https://postimg.cc/SYQJ1Vcx)\n",
    "[![p663.png](https://i.postimg.cc/50Z8fVxf/p663.png)](https://postimg.cc/47QY1j70)\n",
    "[![p664.png](https://i.postimg.cc/66vdYy0q/p664.png)](https://postimg.cc/fkMtbW1Q)\n",
    "[![p665.png](https://i.postimg.cc/SNbc5kTr/p665.png)](https://postimg.cc/6Tz74JN2)\n",
    "[![p666.png](https://i.postimg.cc/BQ52fkRG/p666.png)](https://postimg.cc/Yh9v1npX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 5: Ejecutar el Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Ejecutar el Pipeline**: Haz clic en el botón **\"Debug\"** en la parte superior para ejecutar el pipeline en modo de depuración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p667.png](https://i.postimg.cc/T3RgdQX5/p667.png)](https://postimg.cc/9rnr1d0c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 6: Revisar los Resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Revisar loa resultados**:\n",
    "\n",
    "   - Después de que el pipeline se ejecute, podrás ver los resultados en la sección de **Details**.\n",
    "   - Podemos ver que en total se cargaron 59 registros y la columna **Date** de la tabla no tiene valores, ya que omitimos esa columna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p668.png](https://i.postimg.cc/GmqYHYc7/p668.png)](https://postimg.cc/dhZDfhZr)\n",
    "[![p669.png](https://i.postimg.cc/jj2fN52s/p669.png)](https://postimg.cc/06gr1973)\n",
    "[![p670.png](https://i.postimg.cc/N0nHxc2R/p670.png)](https://postimg.cc/f3xyw1Kb)\n",
    "[![p671.png](https://i.postimg.cc/MTjjPF1N/p671.png)](https://postimg.cc/2br63Tc7)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
