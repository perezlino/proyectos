{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`Paso 5`: Transformación de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Transformación de datos utilizando un `Spark Pool`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 1 - Acceder a Azure Synapse Studio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Abrir Azure Synapse Studio**: \n",
    "    - Regresa al Azure Portal y busca `All resources`.\n",
    "    - Selecciona tu instancia de **Azure Synapse Workspace**.\n",
    "    - Haz clic en `Abrir Synapse Studio` para acceder a la interfaz de usuario de Synapse Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1193.png](https://i.postimg.cc/VLZz2B6b/p1193.png)](https://postimg.cc/KRLXMTtZ)\n",
    "[![p1185.png](https://i.postimg.cc/tTYnPCYs/p1185.png)](https://postimg.cc/tZGgGbdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 2 - Navegar a la sección \"Manage\" y crear un \"Spark pool\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dentro de Synapse Studio, en el panel izquierdo, selecciona la opción `Managed`.\n",
    "2. En el panel de `Managed`, encontrarás varias secciones, nos interesa la sección **Analytics pools** donde encontrarás `Apache Spark pools`.\n",
    "1. Haz clic en `Apache Spark pools`.\n",
    "2. Luego, selecciona `+ New`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1227.png](https://i.postimg.cc/fRSBTPW0/p1227.png)](https://postimg.cc/9DVGLJ7W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 3: Configuración del Spark Pool**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Aquí configurarás varios parámetros esenciales para el **Spark Pool**.\n",
    "   - **Spache Spark pool name**: Introduce un **nombre único** para tu Spark Pool. Asegúrate de que sea fácil de identificar. LLevará por nombre `sparkpool`.\n",
    "   - **Node size family**: Debemos seleccionar el tipo de nodos para tu pool. Hay dos familias principales de nodos:\n",
    "     - **Optimizado para memoria**: Ideal para trabajos que requieren más memoria RAM.\n",
    "     - **Acelerado por hardware**: Para trabajos que necesitan unidades de procesamiento gráfico (GPU).\n",
    "   - Si no necesitas capacidades de GPU, selecciona **Optimizado para memoria** para reducir costos.\n",
    "   - **Tamaño de los nodos**: Aquí defines el **número de núcleos de CPU** y la cantidad de **memoria** por nodo. Por ejemplo, podrías elegir 4 núcleos y 32 GB de memoria para cada nodo.\n",
    "   - **Autoscale**: Deshabilitamos la opción de **Autoscale**, que ajusta automáticamente el número de nodos según la carga de trabajo (workload).\n",
    "   - **Número de nodos**: Define cuántos nodos deseas tener en tu Spark Pool. Dependiendo del tamaño de tus datos, puedes seleccionar entre 3 y 10 nodos. Ten en cuenta que uno de estos nodos será el **nodo driver**, mientras que el resto serán **nodos worker**.\n",
    "   - **Dinamically allocate executors**: Lo deshabilitamos.\n",
    "\n",
    "2. **Configuración adicional**: Si lo necesitas, puedes configurar opciones adicionales como:\n",
    "   - **Automatic pausing**: Habilitamos la opción de pausar el Spark pool de manera automatica.\n",
    "   - **Number of minutes idle**: El tiempo durante el cual el pool permanecerá activo antes de ser pausado.\n",
    "\n",
    "3. **Revisión**: Después de haber configurado todas las opciones, revisa la configuración del Spark Pool y asegúrate de que todo esté correcto.\n",
    "\n",
    "4. **Crear el Spark Pool**:\n",
    "   - Una vez revisada la configuración, haz clic en **\"Crear\"** para iniciar la creación del Spark Pool.\n",
    "   - **Espera unos minutos** hasta que el pool se cree correctamente. Una vez creado, el Spark Pool estará listo para usarse en tus trabajos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1228.png](https://i.postimg.cc/ydsPjYmF/p1228.png)](https://postimg.cc/KKpBvbsz)\n",
    "[![p1229.png](https://i.postimg.cc/1zxMgK47/p1229.png)](https://postimg.cc/yDP0tcm0)\n",
    "[![p1230.png](https://i.postimg.cc/d169xP6g/p1230.png)](https://postimg.cc/ph98mSgB)\n",
    "[![p1231.png](https://i.postimg.cc/yNFj0SZ1/p1231.png)](https://postimg.cc/zLGTrv76)\n",
    "[![p1232.png](https://i.postimg.cc/KjsDmPdN/p1232.png)](https://postimg.cc/YLYW3W2G)\n",
    "[![p1233.png](https://i.postimg.cc/0jNCgWHj/p1233.png)](https://postimg.cc/47rcV5GR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 4 - Creación de un notebook para \"manejo de valores nulos\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dirigirse a la sección **Develop** dentro de Synapse Studio.\n",
    "2. Dentro de la sección **Develop**, haz clic en el botón `+ New` y selecciona `Notebook`. Puedes adjuntar el Spark Pool creado a dicho notebook.\n",
    "3. El notebook llevará por nombre `1_Handling_nulls_duplicates_and_aggregations`\n",
    "4. Dentro del notebook, puedes ejecutar una celda de código Spark. Esto iniciará automáticamente el Spark Pool y cambiará su estado a **Activo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1234.png](https://i.postimg.cc/d0g1c4Q6/p1234.png)](https://postimg.cc/1gcPp0qV)\n",
    "[![p1235.png](https://i.postimg.cc/FRcKr374/p1235.png)](https://postimg.cc/62WKz7rj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ejecutamos nuestro código:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1236.png](https://i.postimg.cc/FFVL0XHQ/p1236.png)](https://postimg.cc/c66CNj3D)\n",
    "[![p1237.png](https://i.postimg.cc/TY2W9NK5/p1237.png)](https://postimg.cc/9zSMXptc)\n",
    "[![p1238.png](https://i.postimg.cc/132ny9JD/p1238.png)](https://postimg.cc/751YVyvL)\n",
    "[![p1239.png](https://i.postimg.cc/YqXLyNFn/p1239.png)](https://postimg.cc/QHTMFT01)\n",
    "[![p1240.png](https://i.postimg.cc/BnXPW8cq/p1240.png)](https://postimg.cc/FYXH3HBq)\n",
    "[![p1241.png](https://i.postimg.cc/bvnGJKBW/p1241.png)](https://postimg.cc/Z9TYsDZx)\n",
    "[![p1242.png](https://i.postimg.cc/26f1B0p6/p1242.png)](https://postimg.cc/8Ftp2BzQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Verificamos que el directorio `NoNulls` y el archivo `parquet` sin valores nulos se hayan creado correctamente en el contenedor **refined**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1244.png](https://i.postimg.cc/3JPYRdQr/p1244.png)](https://postimg.cc/56qZK9tD)\n",
    "[![p1245.png](https://i.postimg.cc/52L1FbfB/p1245.png)](https://postimg.cc/qNJWPfhq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 5 - Creación de un notebook para \"modificar valores y renombre de columna\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dirigirse a la sección **Develop** dentro de Synapse Studio.\n",
    "2. Dentro de la sección **Develop**, haz clic en el botón `+ New` y selecciona `Notebook`. Puedes adjuntar el Spark Pool creado a dicho notebook.\n",
    "3. El notebook llevará por nombre `2_Modify_values_and_rename_column`\n",
    "4. Dentro del notebook, puedes ejecutar una celda de código Spark. Esto iniciará automáticamente el Spark Pool y cambiará su estado a **Activo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1243.png](https://i.postimg.cc/DyW7n1DY/p1243.png)](https://postimg.cc/4mTD1HXz)\n",
    "[![p1246.png](https://i.postimg.cc/s2tZVVft/p1246.png)](https://postimg.cc/FfVKpXLZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ejecutamos nuestro código:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1247.png](https://i.postimg.cc/2yxqFhdD/p1247.png)](https://postimg.cc/T5pYTyH7)\n",
    "[![p1248.png](https://i.postimg.cc/50LQyZ6j/p1248.png)](https://postimg.cc/sQfg0HPR)\n",
    "[![p1249.png](https://i.postimg.cc/3Nh4vnv1/p1249.png)](https://postimg.cc/wyWjK5FR)\n",
    "[![p1250.png](https://i.postimg.cc/nVKQJbyP/p1250.png)](https://postimg.cc/dD102Xt2)\n",
    "[![p1251.png](https://i.postimg.cc/YqpL2Dkq/p1251.png)](https://postimg.cc/kDpgfcBk)\n",
    "[![p1252.png](https://i.postimg.cc/HsBcr0s0/p1252.png)](https://postimg.cc/XpB7hC5X)\n",
    "[![p1253.png](https://i.postimg.cc/W1zDgDhB/p1253.png)](https://postimg.cc/dhMtKVR6)\n",
    "[![p1254.png](https://i.postimg.cc/YCPv3pFh/p1254.png)](https://postimg.cc/CRjMMpmg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Verificamos que el directorio `DataTransformed` y el archivo `parquet` transformado se hayan creado correctamente en el contenedor **refined**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1255.png](https://i.postimg.cc/1zNf7L0M/p1255.png)](https://postimg.cc/Mcq6v3Fj)\n",
    "[![p1256.png](https://i.postimg.cc/cHy6pXXW/p1256.png)](https://postimg.cc/qtwkncPD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 6 - Creación de un notebook para \"\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dirigirse a la sección **Develop** dentro de Synapse Studio.\n",
    "2. Dentro de la sección **Develop**, haz clic en el botón `+ New` y selecciona `Notebook`. Puedes adjuntar el Spark Pool creado a dicho notebook.\n",
    "3. El notebook llevará por nombre ``\n",
    "4. Dentro del notebook, puedes ejecutar una celda de código Spark. Esto iniciará automáticamente el Spark Pool y cambiará su estado a **Activo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ejecutamos nuestro código:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Verificamos que el directorio `DataTransformed` y el archivo `parquet` transformado se hayan creado correctamente en el contenedor **refined**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
