{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`Paso 5`: Transformación de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Transformación de datos utilizando un `Spark Pool`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 1 - Acceder a Azure Synapse Studio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Abrir Azure Synapse Studio**: \n",
    "    - Regresa al Azure Portal y busca `All resources`.\n",
    "    - Selecciona tu instancia de **Azure Synapse Workspace**.\n",
    "    - Haz clic en `Abrir Synapse Studio` para acceder a la interfaz de usuario de Synapse Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1193.png](https://i.postimg.cc/VLZz2B6b/p1193.png)](https://postimg.cc/KRLXMTtZ)\n",
    "[![p1185.png](https://i.postimg.cc/tTYnPCYs/p1185.png)](https://postimg.cc/tZGgGbdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 2 - Navegar a la sección \"Manage\" y crear un \"Spark pool\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dentro de Synapse Studio, en el panel izquierdo, selecciona la opción `Managed`.\n",
    "2. En el panel de `Managed`, encontrarás varias secciones, nos interesa la sección **Analytics pools** donde encontrarás `Apache Spark pools`.\n",
    "1. Haz clic en `Apache Spark pools`.\n",
    "2. Luego, selecciona `+ New`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1227.png](https://i.postimg.cc/fRSBTPW0/p1227.png)](https://postimg.cc/9DVGLJ7W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 3: Configuración del Spark Pool**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Aquí configurarás varios parámetros esenciales para el **Spark Pool**.\n",
    "   - **Spache Spark pool name**: Introduce un **nombre único** para tu Spark Pool. Asegúrate de que sea fácil de identificar. LLevará por nombre `sparkpool`.\n",
    "   - **Node size family**: Debemos seleccionar el tipo de nodos para tu pool. Hay dos familias principales de nodos:\n",
    "     - **Optimizado para memoria**: Ideal para trabajos que requieren más memoria RAM.\n",
    "     - **Acelerado por hardware**: Para trabajos que necesitan unidades de procesamiento gráfico (GPU).\n",
    "   - Si no necesitas capacidades de GPU, selecciona **Optimizado para memoria** para reducir costos.\n",
    "   - **Tamaño de los nodos**: Aquí defines el **número de núcleos de CPU** y la cantidad de **memoria** por nodo. Por ejemplo, podrías elegir 4 núcleos y 32 GB de memoria para cada nodo.\n",
    "   - **Autoscale**: Deshabilitamos la opción de **Autoscale**, que ajusta automáticamente el número de nodos según la carga de trabajo (workload).\n",
    "   - **Número de nodos**: Define cuántos nodos deseas tener en tu Spark Pool. Dependiendo del tamaño de tus datos, puedes seleccionar entre 3 y 10 nodos. Ten en cuenta que uno de estos nodos será el **nodo driver**, mientras que el resto serán **nodos worker**.\n",
    "   - **Dinamically allocate executors**: Lo deshabilitamos.\n",
    "\n",
    "2. **Configuración adicional**: Si lo necesitas, puedes configurar opciones adicionales como:\n",
    "   - **Automatic pausing**: Habilitamos la opción de pausar el Spark pool de manera automatica.\n",
    "   - **Number of minutes idle**: El tiempo durante el cual el pool permanecerá activo antes de ser pausado.\n",
    "\n",
    "3. **Revisión**: Después de haber configurado todas las opciones, revisa la configuración del Spark Pool y asegúrate de que todo esté correcto.\n",
    "\n",
    "4. **Crear el Spark Pool**:\n",
    "   - Una vez revisada la configuración, haz clic en **\"Crear\"** para iniciar la creación del Spark Pool.\n",
    "   - **Espera unos minutos** hasta que el pool se cree correctamente. Una vez creado, el Spark Pool estará listo para usarse en tus trabajos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1228.png](https://i.postimg.cc/ydsPjYmF/p1228.png)](https://postimg.cc/KKpBvbsz)\n",
    "[![p1229.png](https://i.postimg.cc/1zxMgK47/p1229.png)](https://postimg.cc/yDP0tcm0)\n",
    "[![p1230.png](https://i.postimg.cc/d169xP6g/p1230.png)](https://postimg.cc/ph98mSgB)\n",
    "[![p1231.png](https://i.postimg.cc/yNFj0SZ1/p1231.png)](https://postimg.cc/zLGTrv76)\n",
    "[![p1232.png](https://i.postimg.cc/KjsDmPdN/p1232.png)](https://postimg.cc/YLYW3W2G)\n",
    "[![p1233.png](https://i.postimg.cc/0jNCgWHj/p1233.png)](https://postimg.cc/47rcV5GR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 4 - Creación de un notebook para \"manejo de valores nulos\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dirigirse a la sección **Develop** dentro de Synapse Studio.\n",
    "2. Dentro de la sección **Develop**, haz clic en el botón `+ New` y selecciona `Notebook`. Puedes adjuntar el Spark Pool creado a dicho notebook.\n",
    "3. El notebook llevará por nombre `1_Handling_nulls_duplicates_and_aggregations`\n",
    "4. Dentro del notebook, puedes ejecutar una celda de código Spark. Esto iniciará automáticamente el Spark Pool y cambiará su estado a **Activo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1234.png](https://i.postimg.cc/d0g1c4Q6/p1234.png)](https://postimg.cc/1gcPp0qV)\n",
    "[![p1235.png](https://i.postimg.cc/FRcKr374/p1235.png)](https://postimg.cc/62WKz7rj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ejecutamos nuestro código:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1236.png](https://i.postimg.cc/FFVL0XHQ/p1236.png)](https://postimg.cc/c66CNj3D)\n",
    "[![p1237.png](https://i.postimg.cc/TY2W9NK5/p1237.png)](https://postimg.cc/9zSMXptc)\n",
    "[![p1238.png](https://i.postimg.cc/132ny9JD/p1238.png)](https://postimg.cc/751YVyvL)\n",
    "[![p1239.png](https://i.postimg.cc/YqXLyNFn/p1239.png)](https://postimg.cc/QHTMFT01)\n",
    "[![p1240.png](https://i.postimg.cc/BnXPW8cq/p1240.png)](https://postimg.cc/FYXH3HBq)\n",
    "[![p1241.png](https://i.postimg.cc/bvnGJKBW/p1241.png)](https://postimg.cc/Z9TYsDZx)\n",
    "[![p1242.png](https://i.postimg.cc/26f1B0p6/p1242.png)](https://postimg.cc/8Ftp2BzQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Verificamos que el directorio `NoNulls` y el archivo `parquet` sin valores nulos se hayan creado correctamente en el contenedor **refined**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1244.png](https://i.postimg.cc/3JPYRdQr/p1244.png)](https://postimg.cc/56qZK9tD)\n",
    "[![p1245.png](https://i.postimg.cc/52L1FbfB/p1245.png)](https://postimg.cc/qNJWPfhq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 5 - Creación de un notebook para \"modificar valores y renombre de columna\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dirigirse a la sección **Develop** dentro de Synapse Studio.\n",
    "2. Dentro de la sección **Develop**, haz clic en el botón `+ New` y selecciona `Notebook`. Puedes adjuntar el Spark Pool creado a dicho notebook.\n",
    "3. El notebook llevará por nombre `2_Modify_values_and_rename_column`\n",
    "4. Dentro del notebook, puedes ejecutar una celda de código Spark. Esto iniciará automáticamente el Spark Pool y cambiará su estado a **Activo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1243.png](https://i.postimg.cc/DyW7n1DY/p1243.png)](https://postimg.cc/4mTD1HXz)\n",
    "[![p1246.png](https://i.postimg.cc/s2tZVVft/p1246.png)](https://postimg.cc/FfVKpXLZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ejecutamos nuestro código:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1247.png](https://i.postimg.cc/2yxqFhdD/p1247.png)](https://postimg.cc/T5pYTyH7)\n",
    "[![p1248.png](https://i.postimg.cc/50LQyZ6j/p1248.png)](https://postimg.cc/sQfg0HPR)\n",
    "[![p1249.png](https://i.postimg.cc/3Nh4vnv1/p1249.png)](https://postimg.cc/wyWjK5FR)\n",
    "[![p1250.png](https://i.postimg.cc/nVKQJbyP/p1250.png)](https://postimg.cc/dD102Xt2)\n",
    "[![p1251.png](https://i.postimg.cc/YqpL2Dkq/p1251.png)](https://postimg.cc/kDpgfcBk)\n",
    "[![p1252.png](https://i.postimg.cc/HsBcr0s0/p1252.png)](https://postimg.cc/XpB7hC5X)\n",
    "[![p1253.png](https://i.postimg.cc/W1zDgDhB/p1253.png)](https://postimg.cc/dhMtKVR6)\n",
    "[![p1254.png](https://i.postimg.cc/YCPv3pFh/p1254.png)](https://postimg.cc/CRjMMpmg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Verificamos que el directorio `DataTransformed` y el archivo `parquet` transformado se hayan creado correctamente en el contenedor **refined**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1255.png](https://i.postimg.cc/1zNf7L0M/p1255.png)](https://postimg.cc/Mcq6v3Fj)\n",
    "[![p1256.png](https://i.postimg.cc/cHy6pXXW/p1256.png)](https://postimg.cc/qtwkncPD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 6 - Creación de un notebook para \"realizar una transformación de tipo join para incorporar una nueva columna al dataset original\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dirigirse a la sección **Develop** dentro de Synapse Studio.\n",
    "2. Dentro de la sección **Develop**, haz clic en el botón `+ New` y selecciona `Notebook`. Puedes adjuntar el Spark Pool creado a dicho notebook.\n",
    "3. El notebook llevará por nombre `3_Performing_Join_Transformation`\n",
    "4. Dentro del notebook, puedes ejecutar una celda de código Spark. Esto iniciará automáticamente el Spark Pool y cambiará su estado a **Activo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1259.png](https://i.postimg.cc/V61n4dcz/p1259.png)](https://postimg.cc/kV12gM4H)\n",
    "[![p1260.png](https://i.postimg.cc/4d5t0sJV/p1260.png)](https://postimg.cc/njXCj89h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Creación del directorio `ForJoins` dentro del contenedor `refined` y carga del archivo `Education_and_expected_salary_ranges.csv`, que se utilizará para la operación de tipo **Join**.\n",
    "\n",
    "   - Accede a la sección **Data**.\n",
    "   - En la pestaña **Linked**, haz clic en el botón `Azure Data Lake Storage Gen2` y selecciona el contenedor `refined`.\n",
    "   - Dentro del contenedor `refined`, haz clic en el botón `+ New folder` y crea un directorio llamado `ForJoins`.\n",
    "   - Carga el archivo `Education_and_expected_salary_ranges.csv` en el directorio recién creado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1261.png](https://i.postimg.cc/vTZ9FkBj/p1261.png)](https://postimg.cc/wyn3DWDc)\n",
    "[![p1262.png](https://i.postimg.cc/jqMPQx3r/p1262.png)](https://postimg.cc/K4g1m2y9)\n",
    "[![p1263.png](https://i.postimg.cc/wM4N62RB/p1263.png)](https://postimg.cc/n97r2vk8)\n",
    "[![p1264.png](https://i.postimg.cc/MKXR9Cgf/p1264.png)](https://postimg.cc/qzVzR5Jp)\n",
    "[![p1265.png](https://i.postimg.cc/nc5mgdtR/p1265.png)](https://postimg.cc/0bYrJ0jD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Ejecutamos nuestro código:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1266.png](https://i.postimg.cc/8z6vShp1/p1266.png)](https://postimg.cc/HrTn088K)\n",
    "[![p1267.png](https://i.postimg.cc/KYhMvRjt/p1267.png)](https://postimg.cc/hXMj249G)\n",
    "[![p1268.png](https://i.postimg.cc/Y9pLYZ19/p1268.png)](https://postimg.cc/gwT0PMtF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Verificamos que el directorio `JoinedData` y el archivo `parquet` transformado se hayan creado correctamente en el contenedor **refined**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1269.png](https://i.postimg.cc/1z0NgsV2/p1269.png)](https://postimg.cc/06QNFgf0)\n",
    "[![p1270.png](https://i.postimg.cc/76mGV9VN/p1270.png)](https://postimg.cc/47Hx4zjK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 7 - Creación de un notebook para \"manipulación de strings y ordenación\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dirigirse a la sección **Develop** dentro de Synapse Studio.\n",
    "2. Dentro de la sección **Develop**, haz clic en el botón `+ New` y selecciona `Notebook`. Puedes adjuntar el Spark Pool creado a dicho notebook.\n",
    "3. El notebook llevará por nombre `4_String_manipulation_and_Sorting`\n",
    "4. Dentro del notebook, puedes ejecutar una celda de código Spark. Esto iniciará automáticamente el Spark Pool y cambiará su estado a **Activo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1271.png](https://i.postimg.cc/P5Pgr59f/p1271.png)](https://postimg.cc/NKvJdBQZ)\n",
    "[![p1272.png](https://i.postimg.cc/Jzv9yWCN/p1272.png)](https://postimg.cc/gxyM5QJj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ejecutamos nuestro código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1273.png](https://i.postimg.cc/d1mXSkk6/p1273.png)](https://postimg.cc/47yBY31H)\n",
    "[![p1274.png](https://i.postimg.cc/bvn4kFqK/p1274.png)](https://postimg.cc/WD29P8Fn)\n",
    "[![p1275.png](https://i.postimg.cc/vBdkzLBD/p1275.png)](https://postimg.cc/XZQsN590)\n",
    "[![p1276.png](https://i.postimg.cc/tJqf0qFj/p1276.png)](https://postimg.cc/8JYwMVyK)\n",
    "[![p1277.png](https://i.postimg.cc/hv2Yck07/p1277.png)](https://postimg.cc/wRs2kbZ6)\n",
    "[![p1278.png](https://i.postimg.cc/KcfwPTyv/p1278.png)](https://postimg.cc/Z09wZCR1)\n",
    "[![p1279.png](https://i.postimg.cc/sD28w2VP/p1279.png)](https://postimg.cc/nM60Lp9M)\n",
    "[![p1280.png](https://i.postimg.cc/HsPNKCxq/p1280.png)](https://postimg.cc/hfTMz6Vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Verificamos que el directorio `StringSorted` y el archivo `parquet` transformado se hayan creado correctamente en el contenedor **refined**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1281.png](https://i.postimg.cc/wjyrYbR7/p1281.png)](https://postimg.cc/7549g9Vk)\n",
    "[![p1282.png](https://i.postimg.cc/13kjmcDM/p1282.png)](https://postimg.cc/Hrt23MZ7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 8 - Creación de un notebook para \"aplicación de la función Window y cálculo de Dense Rank\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dirigirse a la sección **Develop** dentro de Synapse Studio.\n",
    "2. Dentro de la sección **Develop**, haz clic en el botón `+ New` y selecciona `Notebook`. Puedes adjuntar el Spark Pool creado a dicho notebook.\n",
    "3. El notebook llevará por nombre `5_Window_function_and_calculation_of_Dense_Rank`\n",
    "4. Dentro del notebook, puedes ejecutar una celda de código Spark. Esto iniciará automáticamente el Spark Pool y cambiará su estado a **Activo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1283.png](https://i.postimg.cc/8PJCxN4W/p1283.png)](https://postimg.cc/Vdw1Cy3L)\n",
    "[![p1284.png](https://i.postimg.cc/RVk0BypY/p1284.png)](https://postimg.cc/svJzP6rP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ejecutamos nuestro código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1285.png](https://i.postimg.cc/hjsrF9SC/p1285.png)](https://postimg.cc/zbLWKHHW)\n",
    "[![p1286.png](https://i.postimg.cc/2y5xCVyC/p1286.png)](https://postimg.cc/MMhBDZ1L)\n",
    "[![p1287.png](https://i.postimg.cc/8Pjb3JxH/p1287.png)](https://postimg.cc/1f16Vtmn)\n",
    "[![p1288.png](https://i.postimg.cc/DfCgBdp0/p1288.png)](https://postimg.cc/grZ80RWb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Verificamos que el directorio `WindowFunctions` y el archivo `parquet` transformado se hayan creado correctamente en el contenedor **refined**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1289.png](https://i.postimg.cc/1XYrXsVw/p1289.png)](https://postimg.cc/kRKbhrcg)\n",
    "[![p1290.png](https://i.postimg.cc/9FKBjXhj/p1290.png)](https://postimg.cc/Vd9tq8v7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 9 - Creación de un notebook para \"conversión de columna de tipo String a Date\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dirigirse a la sección **Develop** dentro de Synapse Studio.\n",
    "2. Dentro de la sección **Develop**, haz clic en el botón `+ New` y selecciona `Notebook`. Puedes adjuntar el Spark Pool creado a dicho notebook.\n",
    "3. El notebook llevará por nombre `6_Conversion_of_column_from_String_to_Date`\n",
    "4. Dentro del notebook, puedes ejecutar una celda de código Spark. Esto iniciará automáticamente el Spark Pool y cambiará su estado a **Activo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1291.png](https://i.postimg.cc/BvPSV00b/p1291.png)](https://postimg.cc/Y4kBvTjB)\n",
    "[![p1292.png](https://i.postimg.cc/ZRkbkMbc/p1292.png)](https://postimg.cc/Y43KY8mG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ejecutamos nuestro código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1293.png](https://i.postimg.cc/4ysXyHhH/p1293.png)](https://postimg.cc/gXSCBJsG)\n",
    "[![p1294.png](https://i.postimg.cc/cCh0n1Q9/p1294.png)](https://postimg.cc/jnDpVb3P)\n",
    "[![p1295.png](https://i.postimg.cc/QtpXjJVr/p1295.png)](https://postimg.cc/Pp5G4Zm6)\n",
    "[![p1296.png](https://i.postimg.cc/L43H7Drt/p1296.png)](https://postimg.cc/V55Q0qsv)\n",
    "[![p1297.png](https://i.postimg.cc/6569NRXD/p1297.png)](https://postimg.cc/DmDVrSmg)\n",
    "[![p1298.png](https://i.postimg.cc/9FxcXMXz/p1298.png)](https://postimg.cc/Czf3mwqV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Verificamos que el directorio `WindowFunctions` y el archivo `parquet` transformado se hayan creado correctamente en el contenedor **refined**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1299.png](https://i.postimg.cc/zGV8yr37/p1299.png)](https://postimg.cc/ZWt1QX8v)\n",
    "[![p1300.png](https://i.postimg.cc/vZkM9NVs/p1300.png)](https://postimg.cc/VJq3P4gG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 10 - Creación de un notebook para \"definición y gestión del schema\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dirigirse a la sección **Develop** dentro de Synapse Studio.\n",
    "2. Dentro de la sección **Develop**, haz clic en el botón `+ New` y selecciona `Notebook`. Puedes adjuntar el Spark Pool creado a dicho notebook.\n",
    "3. El notebook llevará por nombre `7_Schema_definition_and_management`\n",
    "4. Dentro del notebook, puedes ejecutar una celda de código Spark. Esto iniciará automáticamente el Spark Pool y cambiará su estado a **Activo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1301.png](https://i.postimg.cc/d31S5JbS/p1301.png)](https://postimg.cc/cgpmHG4Q)\n",
    "[![p1302.png](https://i.postimg.cc/D0MpDtFf/p1302.png)](https://postimg.cc/YLQxLDhT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ejecutamos nuestro código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1303.png](https://i.postimg.cc/SNnv8N7n/p1303.png)](https://postimg.cc/pptCMvSv)\n",
    "[![p1304.png](https://i.postimg.cc/bN4FRc33/p1304.png)](https://postimg.cc/56q3xGcC)\n",
    "[![p1305.png](https://i.postimg.cc/xjxZcbHr/p1305.png)](https://postimg.cc/0rSn4jcZ)\n",
    "[![p1306.png](https://i.postimg.cc/wjJ4ffrH/p1306.png)](https://postimg.cc/WdN7tnjf)\n",
    "[![p1307.png](https://i.postimg.cc/FKVWmfmB/p1307.png)](https://postimg.cc/5HjqS2XB)\n",
    "[![p1308.png](https://i.postimg.cc/MTZsGWpK/p1308.png)](https://postimg.cc/ns5KRfm6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Verificamos que el directorio `WindowFunctions` y el archivo `parquet` transformado se hayan creado correctamente en el contenedor **refined**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1309.png](https://i.postimg.cc/9fh8vP39/p1309.png)](https://postimg.cc/BjmBFKnZ)\n",
    "[![p1310.png](https://i.postimg.cc/50PsYZX5/p1310.png)](https://postimg.cc/WFkGxY6t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 11 - Creación de un notebook para \"escribir el resultado en el contenedor processed\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dirigirse a la sección **Develop** dentro de Synapse Studio.\n",
    "2. Dentro de la sección **Develop**, haz clic en el botón `+ New` y selecciona `Notebook`. Puedes adjuntar el Spark Pool creado a dicho notebook.\n",
    "3. El notebook llevará por nombre `8_Writing_data_to_processed_container`\n",
    "4. Dentro del notebook, puedes ejecutar una celda de código Spark. Esto iniciará automáticamente el Spark Pool y cambiará su estado a **Activo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1311.png](https://i.postimg.cc/ydrTYcGv/p1311.png)](https://postimg.cc/ygcRLgsZ)\n",
    "[![p1312.png](https://i.postimg.cc/T1LJyhMG/p1312.png)](https://postimg.cc/N2tHSsjP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ejecutamos nuestro código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1313.png](https://i.postimg.cc/05FLVwNY/p1313.png)](https://postimg.cc/dDRH1Dr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Verificamos que el directorio `WindowFunctions` y el archivo `parquet` transformado se hayan creado correctamente en el contenedor **refined**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p1314.png](https://i.postimg.cc/WzB60jTZ/p1314.png)](https://postimg.cc/PvMwkgLf)\n",
    "[![p1315.png](https://i.postimg.cc/J7Gf3qR7/p1315.png)](https://postimg.cc/xqVpnLkB)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
