{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`Paso 5.4`: Creación de Pipeline `pl_Copy_Full_IPL_Data_using_DF`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Cargar todos los archivos JSON del contenedor `raw` de nuestro ADLS utilizando `Data Flows`. Para ello creamos un nuevo Pipeline llamado `pl_Copy_Full_IPL_Data_using_DF` en el cual ejecutaremos nuestro Data Flow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 1 - Importar schema del dataset de origen `ds_Valid_IPL_Data_Json`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. En el dataset de origen **ds_Valid_IPL_Data_Json** dejaremos vacio el recuadro del archivo, dado que utilizaremos\n",
    "un comodin para llamar a todos los archivos JSON desde **source** utlizando `Wildcard paths` igual a `*.json` en un **Dataflow** que crearemos en pasos posteriores.\n",
    "\n",
    "2. Es importante también **importar el schema** eligiendo la opción `From files *.json`. Dado que este dataset utilizaba el schema del archivo **ipl 2008.json**, pues esa era la fuente en el paso anterior.\n",
    "\n",
    "| Siempre debemos `IMPORTAR EL SCHEMA DE LAS FUENTES` antes de utilizarlas |\n",
    "|---|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p672.png](https://i.postimg.cc/rsZRkqsw/p672.png)](https://postimg.cc/SY8xLFcB)\n",
    "[![p672-1.png](https://i.postimg.cc/v80V9thw/p672-1.png)](https://postimg.cc/rzts2W7f)\n",
    "[![p672-2.png](https://i.postimg.cc/bNd2RSVD/p672-2.png)](https://postimg.cc/VdQ6fv8m)\n",
    "[![p672-3.png](https://i.postimg.cc/nc59SVNd/p672-3.png)](https://postimg.cc/ykmNkK19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 2 - Truncar tabla `dbo.tbl_IPLData`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Debemos truncar la tabla **dbo.tbl_IPLData** para eliminar todos los registros que fueron cargados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "TRUNCATE TABLE dbo.tbl_IPLData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p673.png](https://i.postimg.cc/y8ZgM4H7/p673.png)](https://postimg.cc/nXnhmWrW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 3 - Crear el Data Flow `df_Copy_IPL_Data`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Seleccionar \"Data flows\"**: En el panel de Authoring, haz clic en **Data flows**.\n",
    "2. **Hacer clic en los tres puntos**: Junto a la opción **Data flows**, haz clic en los tres puntos (más opciones).\n",
    "3. **Seleccionar \"New data flow\"**: En el menú desplegable, selecciona **New data flow** para crear un nuevo data flow. Crea un nuevo Data Flow llamado `df_Copy_IPL_Data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p674.png](https://i.postimg.cc/cJ7KJRCj/p674.png)](https://postimg.cc/06Q5WJpd)\n",
    "[![p675.png](https://i.postimg.cc/xdVJYxfM/p675.png)](https://postimg.cc/rDgFN9tw)\n",
    "[![p676.png](https://i.postimg.cc/W32dqdJ4/p676.png)](https://postimg.cc/t1MqLCk0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 4 - Data flow: Añadir y configurar el componente `Source`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Configuración en la pestaña **Source settings**:\n",
    "\n",
    "    - **Output stream name**: `sourceJson`\n",
    "    - **Source type**: `Dataset`\n",
    "    - **Dataset**: `ds_Valid_IPL_Data_Json`\n",
    "    - **Options**: Activar `Allow schema drift`\n",
    "    - **Sampling**: Activar `Disable` (por defecto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p677.png](https://i.postimg.cc/nz0C4nvG/p677.png)](https://postimg.cc/9RwmV5gD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Configuración en la pestaña **\"Source options\"**:\n",
    "\n",
    "    - **Wildcard paths**: `*.json`. Esto permite que el Data Flow lea todos los archivos JSON en la ruta especificada. Esto es útil si hay múltiples archivos y se desea procesar todos.\n",
    "    - **Column to store file name**: `SourceFileName`. Al añadir esta columna, cada registro incluirá el nombre del archivo de origen, facilitando el rastreo del origen de los datos.\n",
    "    - **After completion**: Seleccionar `No action\"` (por defecto)\n",
    "    - **JSON settings**:\n",
    "        - **Document form**: Seleccionar `Document per line`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p678.png](https://i.postimg.cc/8ccswx4Q/p678.png)](https://postimg.cc/CnyFxP9m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Visualizar la pestaña **\"Projection\"**:\n",
    "\n",
    "    - **Visualizar tipos de datos**: Comprobamos que todos los tipos de datos de la fuente (archivos **json**) son `String`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p679.png](https://i.postimg.cc/fyPyP5q3/p679.png)](https://postimg.cc/1Vpyn0QP)\n",
    "[![p680.png](https://i.postimg.cc/jdWLf0Cy/p680.png)](https://postimg.cc/xc2frZvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Visualizar la pestaña **Data Preview**:\n",
    "\n",
    "    - **Activar Data flow Debug**: Habilitar el `Data flow debug` para visualizar los datos.\n",
    "    - **Identificar valores NULL**: Observa que hay columnas con valores NULL que necesitan ajustes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p681.png](https://i.postimg.cc/jq3DCdqs/p681.png)](https://postimg.cc/23vkKYBJ)\n",
    "[![p683.png](https://i.postimg.cc/NfWL7JrS/p683.png)](https://postimg.cc/9rYWcBbY)\n",
    "[![p684.png](https://i.postimg.cc/dVr3W221/p684.png)](https://postimg.cc/75PqhTQ8)\n",
    "[![p685.png](https://i.postimg.cc/GpR264Kj/p685.png)](https://postimg.cc/gxMmZkfw)\n",
    "[![p686.png](https://i.postimg.cc/PqMxHdFn/p686.png)](https://postimg.cc/XZp3c6bs)\n",
    "[![p687.png](https://i.postimg.cc/hjPGPNHz/p687.png)](https://postimg.cc/zL6Nx2D8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Configuración en la pestaña **Projection**:\n",
    "\n",
    "    - **Modificar tipos de datos**: Utilizar `Overwrite schema` para modificar los tipos de datos de las columnas según sea necesario.\n",
    "    - No sirve de nada modificar el tipo de dato `string` de la columna **Date** al tipo de dato `date`. Se testeo y no se logró nada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p688.png](https://i.postimg.cc/1tC3gJQW/p688.png)](https://postimg.cc/bDnhW0db)\n",
    "[![p690.png](https://i.postimg.cc/mkKZjkhC/p690.png)](https://postimg.cc/rRCLF81w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 5 - Importar schema del dataset de destino `ds_AzureSqlTable_IPL_Data`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importemos el schema de la tabla `dbo.tbla_IPLData` pues es el sink al cual apunta este dataset.\n",
    "\n",
    "| Siempre debemos `IMPORTAR EL SCHEMA YA SEA DE LAS FUENTES COMO DE LOS DESTINOS` antes de utilizarlas |\n",
    "|---|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p696.png](https://i.postimg.cc/8Cw13tj1/p696.png)](https://postimg.cc/gwXFLyV5)\n",
    "[![p697.png](https://i.postimg.cc/fLLwhm9Y/p697.png)](https://postimg.cc/p9wNf9kd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 6 - Data flow: Añadir y configurar el componente `Sink`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Configuración en la pestaña **Sink**:\n",
    "\n",
    "    - **Output stream name**: `sinkdbIPL`\n",
    "    - **Incoming stream**: `sourceJson`\n",
    "    - **Sink type**: `Dataset`\n",
    "    - **Dataset**: `ds_AzureSqlTable_IPL_Data`\n",
    "    - **Options**: Activar `Allow schema drift`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p691.png](https://i.postimg.cc/5NF20Bk3/p691.png)](https://postimg.cc/CzSgrq0B)\n",
    "[![p692.png](https://i.postimg.cc/zGZXRys1/p692.png)](https://postimg.cc/Tp0Xz32k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Configuración en la pestaña **Settings**:\n",
    "\n",
    "    - **Update method**: `Allow insert`\n",
    "    - **Table action**: Seleccionar `None` (por defecto)\n",
    "    - **Use TempDB**: Activar casilla (por defecto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p693.png](https://i.postimg.cc/52B95xJQ/p693.png)](https://postimg.cc/sM2RsCv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Configuración en la pestaña **Errors**:\n",
    "\n",
    "    - Dejar todo como está (sin cambios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p694.png](https://i.postimg.cc/TPTdCZ27/p694.png)](https://postimg.cc/bZFfvVtk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Configuración en la pestaña **Mapping**:\n",
    "\n",
    "    - Mapear columnas desde `sourceJson` a `ds_AzureSqlTable_IPL_Data`\n",
    "    - Vemos que se genera un aviso de advertencia dado que se está generando un conflicto con el tipo de datos `string` de la columna `Date` que proviene de la fuente `sourceJson` y el tipo de datos `date` de la columna de la tabla de destino `dbo.tbl_IPLData`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p698.png](https://i.postimg.cc/nzPnVr4g/p698.png)](https://postimg.cc/cgwpXs5B)\n",
    "[![p699.png](https://i.postimg.cc/5yQbXJp0/p699.png)](https://postimg.cc/4HGr0rDk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 7 - Crear el Pipeline `pl_Copy_Full_IPL_Data_using_DF`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Seleccionar \"Pipelines\"**: En el panel de Authoring, haz clic en **Pipelines**.\n",
    "2. **Hacer clic en los tres puntos**: Junto a la opción **Pipelines**, haz clic en los tres puntos (más opciones).\n",
    "3. **Seleccionar \"New pipeline\"**: En el menú desplegable, selecciona **New pipeline** para crear un nuevo pipeline. Le damos el nombre de `pl_Copy_Full_IPL_Data_using_DF`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p700.png](https://i.postimg.cc/QVLs5znq/p700.png)](https://postimg.cc/JHQ9Cp8y)\n",
    "[![p701.png](https://i.postimg.cc/ZYWd8yM9/p701.png)](https://postimg.cc/8sVcDsDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 8 - Añadir una actividad `Data Flow` al pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Configuración en la pestaña **General**:\n",
    "\n",
    "    - **Name**: `df_Copy_IPL_Data`.\n",
    "\n",
    "2. Configuración en la pestaña **Settings**:\n",
    "\n",
    "    - **Data flow**: `df_Copy_IPL_Data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p702.png](https://i.postimg.cc/wxns0TCw/p702.png)](https://postimg.cc/PNzxqhrD)\n",
    "[![p703.png](https://i.postimg.cc/kgmRPYX8/p703.png)](https://postimg.cc/KR08nNTv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 9: Ejecutar el Pipeline y revisar resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Ejecutar el Pipeline**: Haz clic en el botón **\"Debug\"** en la parte superior para ejecutar el pipeline en modo de depuración.\n",
    "2. **Revisar loa resultados**:\n",
    "\n",
    "   - Después de que el pipeline se ejecute, podrás ver los resultados en la sección de **Data flow details**.\n",
    "   - Podemos ver que en total se cargaron **958** registros y la columna **Date** de la tabla tiene valores nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p704.png](https://i.postimg.cc/02mK31xP/p704.png)](https://postimg.cc/SJSK25Jv)\n",
    "[![p705.png](https://i.postimg.cc/3xF48jdq/p705.png)](https://postimg.cc/nXMcTDKK)\n",
    "[![p706.png](https://i.postimg.cc/Gp3BHBDm/p706.png)](https://postimg.cc/18TRd3Mk)\n",
    "[![p707.png](https://i.postimg.cc/YSXvgpNf/p707.png)](https://postimg.cc/NyHGvvz5)\n",
    "[![p711.png](https://i.postimg.cc/j5mCgZFD/p711.png)](https://postimg.cc/WFm2t6jV)\n",
    "[![p708.png](https://i.postimg.cc/k4BBvkfr/p708.png)](https://postimg.cc/KkhGZp6Q)\n",
    "[![p709.png](https://i.postimg.cc/Xq5qTdRQ/p709.png)](https://postimg.cc/7JxqzGY2)\n",
    "[![p710.png](https://i.postimg.cc/XNBrG6rd/p710.png)](https://postimg.cc/yWB1t5X8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 10 - Data flow: Añadir y configurar el componente `Derived column`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Para solucionar los problemas de datos nulos en **Date** vamos a agregar una actividad `Derived Column`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p712.png](https://i.postimg.cc/15xfD7FT/p712.png)](https://postimg.cc/JtqrLqPc)\n",
    "[![p713.png](https://i.postimg.cc/Yq1jRNfS/p713.png)](https://postimg.cc/XpYV7CPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Configurar la pestaña **Derived column's settings**:\n",
    "\n",
    "    - **Output stream name**: `derivedCorrectDateColumn`\n",
    "    - **Incoming stream**: `sourceJson`\n",
    "    - **Columns**:\n",
    "      - **Column**: `NewDate`\n",
    "      - **Expression**: `toDate(Date, 'dd-MM-yyyy')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p714.png](https://i.postimg.cc/4xsySKBQ/p714.png)](https://postimg.cc/GHgbBp04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Configuración en la pestaña **Mapping**. Mapeamos la columna recién creada con la columna de la tabla de destino:\n",
    "\n",
    "    - **Input column**: `NewDate`.\n",
    "    - **Output column**: `Date`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p716.png](https://i.postimg.cc/pddTPwN9/p716.png)](https://postimg.cc/fV6ZKgRZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Visualizamos la pestaña **Data Preview**\n",
    "\n",
    "    - Verificamos que la columna `MatchDate` se haya cargado correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p717.png](https://i.postimg.cc/nzjhDqhp/p717.png)](https://postimg.cc/HcmmGcMh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 11 - Truncar tabla `dbo.tbl_IPLData`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Debemos truncar la tabla **dbo.tbl_IPLData** para eliminar todos los registros que fueron cargados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "TRUNCATE TABLE dbo.tbl_IPLData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p718.png](https://i.postimg.cc/zfPfvx5x/p718.png)](https://postimg.cc/yJcKrXDR)\n",
    "[![p719.png](https://i.postimg.cc/Kz6vr41L/p719.png)](https://postimg.cc/sQJr3j9D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 12 - Ejecutar el Pipeline nuevamente y revisar resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Ejecutar el Pipeline**: Haz clic en el botón **\"Debug\"** en la parte superior para ejecutar el pipeline en modo de depuración.\n",
    "2. **Revisar loa resultados**:\n",
    "\n",
    "   - Después de que el pipeline se ejecute, podrás ver los resultados en la sección de **Data flow details**.\n",
    "   - Podemos ver que en total se cargaron **958** registros y la columna **MatchDate** de la tabla se muestra correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![p720.png](https://i.postimg.cc/Gtv3MrDf/p720.png)](https://postimg.cc/tnCHTK2d)\n",
    "[![p721.png](https://i.postimg.cc/G3Dp3Pfj/p721.png)](https://postimg.cc/QVXD07hB)\n",
    "[![p722.png](https://i.postimg.cc/X70YrGS6/p722.png)](https://postimg.cc/w30pPBjw)\n",
    "[![p723.png](https://i.postimg.cc/Wb6bgNTF/p723.png)](https://postimg.cc/F7z4QQfN)\n",
    "[![p724.png](https://i.postimg.cc/6pMWbM7B/p724.png)](https://postimg.cc/SnzbJ77P)\n",
    "[![p725.png](https://i.postimg.cc/L894Vc8y/p725.png)](https://postimg.cc/KRWyGsLL)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
